{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis\n",
    "\n",
    "First, we save in both a CSV and a XLSX file the predictions for every class: in this way, we can see exactly with how much certainty the ML model predicts a class over the other two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- IMPORT LIBRARIES\n",
    "from transformers import pipeline,AutoImageProcessor,AutoModelForImageClassification\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========\n",
    "# =============\n",
    "# ================== VARIABLES\n",
    "# =============\n",
    "# =========\n",
    "\n",
    "CHECKPOINT = './VALIDATION-baseC1-w_40e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "from datasets import load_dataset\n",
    "\n",
    "train_ds = load_dataset('imagefolder', data_dir='./dataset_binary/', split='train', streaming=True)\n",
    "# ---- CHECKING CONVERSION FROM INTEGER VALUE TO LABEL NAME\n",
    "\n",
    "labels = train_ds.features['label']\n",
    "\n",
    "x = labels.int2str(0) # not sensitive\n",
    "y = labels.int2str(1) # sensitive\n",
    "# z = labels.int2str(2) # To be used only for a threeway classification \n",
    "\n",
    "print(\"Integer '0' is label '{x}'\\nInteger '1' is label '{y}'\".format(x=x, y=y)) # \\nInteger '2' is label '{z}' + z=z \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- LOAD IMAGE PROCESSOR\n",
    "finetuned_image_processor = AutoImageProcessor.from_pretrained(CHECKPOINT)\n",
    "\n",
    "\n",
    "# ---- LOAD MODEL\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    CHECKPOINT,\n",
    "    label2id={\"not-sensitive\":0, \"sensitive\":1},\n",
    "    id2label={0:\"not-sensitive\", 1:\"sensitive\"},\n",
    ")\n",
    "\n",
    "\n",
    "pipe = pipeline(\"image-classification\", model=model, feature_extractor=finetuned_image_processor)\n",
    "pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all images of a class \n",
    "\n",
    "not_sensitive_path = './dataset_binary/test/not-sensitive/'\n",
    "sensitive_path = './dataset_binary/test/sensitive/'\n",
    "\n",
    "\n",
    "def groupImages(path:str):\n",
    "    img_lst = list()\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        f = os.path.join(path,file)\n",
    "        img_lst.append(f)\n",
    "    return img_lst\n",
    "\n",
    "def restoreFileName(path:str):\n",
    "    abs_path = os.path.abspath(path)\n",
    "    file_name = os.path.basename(abs_path)\n",
    "    return file_name\n",
    "    \n",
    "\n",
    "#dub_img_lst = groupImages(dubious_path)\n",
    "ns_img_lst = groupImages(not_sensitive_path)\n",
    "s_img_lst = groupImages(sensitive_path)\n",
    "\n",
    "dataset_imgs = [(ns_img_lst,'not-sensitive'),(s_img_lst,'sensitive')]   #(dub_img_lst,'dubious'),\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def createArray(img_lst:list,annotation_value:str):\n",
    "    # Create temporary lists with the various information\n",
    "    lst1_imgnames = list()\n",
    "    lst2_annotation = list()\n",
    "    lst3_labels = list()\n",
    "    lst4_scores = list()\n",
    "    \n",
    "    # Classes/labels names\n",
    "    classes = ['not-sensitive','sensitive']\n",
    "\n",
    "    # Scroll image list\n",
    "    for image in img_lst:\n",
    "        # Make prediction for that single image using the previously defined pipeline\n",
    "        prediction = pipe(image)\n",
    "        \n",
    "        # Add the static information (image name, true annotation value, different classes)\n",
    "        for i in range(3):\n",
    "            lst1_imgnames.append(restoreFileName(image))\n",
    "            lst2_annotation.append(annotation_value)\n",
    "        for label in classes:\n",
    "            lst3_labels.append(label)\n",
    "            \n",
    "        # Add the scores information: for each of the classes, what is the predicted score by the ML model?\n",
    "            # These 3 scores need to be added in a precise order (corresponding to the classes order: dubious/0, not-sensitive/1, sensitive/2), but they are not always ordered in the pipeline output (list of dictionaries, one for each class)\n",
    "            # First, sort the list of dictionaries by the value of key['label']: luckily, the alphabetical order of the three strings is the desired one (d/0-n/1-s/2)\n",
    "        sorted_prediction = sorted(prediction, key=lambda d:d['label'])\n",
    "        \n",
    "        # Now we can append the scores values to the lst4_scores\n",
    "        for dict in sorted_prediction:\n",
    "            lst4_scores.append(dict['score'])\n",
    "        \n",
    "    # Populate array\n",
    "    arr1_imgnames = np.array(lst1_imgnames)\n",
    "    arr2_annotation = np.array(lst2_annotation)\n",
    "    arr3_labels = np.array(lst3_labels)\n",
    "    arrays = [arr1_imgnames,arr2_annotation,arr3_labels]\n",
    "        \n",
    "    return arrays, lst4_scores\n",
    "\n",
    "\n",
    "\"\"\" for lst,ann in tqdm(dataset_imgs):\n",
    "    arrays, lst4_scores = createArray(lst,ann)\n",
    "    df = pd.DataFrame(lst4_scores,index=arrays,columns=['scores'])\n",
    "    df.to_excel('VALIDATION-baseC1-w_40e', merge_cells = True)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrong predictions\n",
    "\n",
    "However, we are interested specifically in all the images which have been predicted *wrongly*. We save the results in a pandas dataframe which then we export both as a CSV and as an Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wrong_predictions = pd.DataFrame(columns=['image','annotation value','predicted label','score'])\n",
    "\n",
    "for lst,ann in dataset_imgs:\n",
    "    for img in lst:\n",
    "        preds = pipe(img,top_k=1)\n",
    "        for dict in preds:\n",
    "            if dict['label'] != ann:\n",
    "                wrong_predictions.loc[len(wrong_predictions.index)] = [restoreFileName(img), ann, dict['label'],dict['score']]  \n",
    "\n",
    "wrong_predictions.to_excel('./valid_error_analysis.xlsx',index=False)\n",
    "wrong_predictions.to_csv('./valid_error_analysis',index=False)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
